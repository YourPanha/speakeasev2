Sign Language Communication & Learning Platform

Overview

This project is a web-based platform designed to bridge the communication gap for people who are deaf or hard of hearing. It provides various accessibility features, including:

Sign-to-Text & Speech: Converts sign language gestures into text and speech for seamless communication.
Text-to-Animated Sign Language: Translates written text into animated sign language, making content more accessible.
End-to-End Video Calling: Integrated video call feature for those who cannot speak or face difficulties with sign-to-text conversion.
Learning Platform: A dedicated section to help users learn sign language interactively.
AI Chatbot: A chatbot specifically designed to assist users with queries related to the platform and sign language.

Features

Real-time sign language recognition.
Text and speech conversion for improved accessibility.
Interactive sign language animations.
Secure and easy-to-use video calling system.
AI-powered chatbot for guidance and support.
Learning modules for sign language education.

Technologies Used
This project leverages various modern technologies and libraries, including:

Frontend

Next.js – For building the user interface.
Tailwind CSS – For a responsive and sleek design.
React Three FIber – For rendering animated sign language characters.

Backend

Node.js & Express.js – For handling server-side operations.
MongoDB – For storing user data and chat history.
WebRTC – For real-time video communication (serverless)
Socket.io - for setting up realtime communication
FastApi - for setting up connection between python and web

AI & ML

TensorFlow.js – For real-time sign language recognition.
MediaPipe – For hand-tracking and gesture recognition.
OpenAI API – For enhancing chatbot responses.
OpenCV - Enabling and processing camera
NumPy - for calculations
Pyttsx3 - for text to speech
